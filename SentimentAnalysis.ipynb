{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note - Don't run the cells as a live demo - some tasks can take 10 minutes or longer...\n",
    "# Text Classification\n",
    "- applying machine learning to classifiy natural language for various tasks\n",
    "- a comprehensive article on Text Classification: https://arxiv.org/pdf/2004.03705.pdf\n",
    "- some common text classification tasks:\n",
    "    1. sentiment analysis\n",
    "    2. news categorization\n",
    "    3. topic analysis\n",
    "    4. question answering (QA)\n",
    "    5. natural language inference (NLI)\n",
    "    \n",
    "## Sentiment Analysis\n",
    "- subfield of **natural language processing (NLP)** \n",
    "- also called **opinion mining**\n",
    "- apply ML algorithms to classify documents based on their polarity:\n",
    "    - the attitude of the writer\n",
    "\n",
    "## General steps\n",
    "1. clean and prepare text data\n",
    "2. build feature vectors from text documents\n",
    "3. train a machine learning model to classify positive and negative movie reviews\n",
    "4. test and evaluate the model\n",
    "\n",
    "## IMDb dataset\n",
    "- contains 50,000 labeled moview reviews from Internet Moview Database (IMDb)\n",
    "- task is to classify reviews as **positive** or **negative**\n",
    "- compressed archive can be downloaded from: http://ai.stanford.edu/~amaas/data/sentiment\n",
    "\n",
    "\n",
    "### Download and untar IMDb dataset\n",
    "- on Linux and Mac use the following cells\n",
    "- on Windows, manually download the archive and untar using 7Zip or other application\n",
    "- or use the provided Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0  1335k      0  0:01:01  0:01:01 --:--:--  970k 0  1011k      0  0:01:21  0:00:11  0:01:10 1545k  0  1484k      0  0:00:55  0:00:34  0:00:21  908k  1469k      0  0:00:55  0:00:38  0:00:17 1236k  0:00:39  0:00:16 1445k\n"
     ]
    }
   ],
   "source": [
    "# let's download the file\n",
    "# FYI - file is ~ 84 MB; takes a while...\n",
    "! curl -o data/aclImdb_v1.tar.gz http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz         titanic.csv               wdbc.data\r\n",
      "melb_data.csv             titanic.xlsx              wdbc.names\r\n",
      "melbourne-housingdata.zip titanic_sorted_age.xlsx\r\n"
     ]
    }
   ],
   "source": [
    "# let's see the contents of the data folder\n",
    "! ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's untar the compressed aclImdb_v1.tar.gz file\n",
    "! tar -zxf data/aclImdb_v1.tar.gz --directory data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option Python code to download and extract tar file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "source = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "target = 'data/aclImdb_v1.tar.gz'\n",
    "\n",
    "\n",
    "def reporthook(count, block_size, total_size):\n",
    "    global start_time\n",
    "    if count == 0:\n",
    "        start_time = time.time()\n",
    "        return\n",
    "    duration = time.time() - start_time\n",
    "    progress_size = int(count * block_size)\n",
    "    speed = progress_size / (1024.**2 * duration)\n",
    "    percent = count * block_size * 100. / total_size\n",
    "\n",
    "    sys.stdout.write(\"\\r%d%% | %d MB | %.2f MB/s | %d sec elapsed\" %\n",
    "                    (percent, progress_size / (1024.**2), speed, duration))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "if not os.path.isdir('data/aclImdb') and not os.path.isfile(target):\n",
    "    urllib.request.urlretrieve(source, target, reporthook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untar the file\n",
    "if not os.path.isdir('data/aclImdb'): # if the directory doesn't exist untar the target to path\n",
    "    with tarfile.open(target, 'r:gz') as tar:\n",
    "        tar.extractall(path=\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the movie dataset into a more convenient format\n",
    "- extract and load the movie dataset into Pandas DataFrame\n",
    "- NOTE: can take up to **10 minutes**\n",
    "- use Pthon Progress Indicator (PyPrind) package to show progress bar from Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyprind\n",
      "  Using cached PyPrind-2.11.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: pyprind\n",
      "Successfully installed pyprind-2.11.2\n"
     ]
    }
   ],
   "source": [
    "! pip install pyprind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:47\n"
     ]
    }
   ],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# change the `basepath` to the directory of the\n",
    "# unzipped movie dataset\n",
    "\n",
    "basepath = 'data/aclImdb'\n",
    "\n",
    "labels = {'pos': 1, 'neg': 0}\n",
    "pbar = pyprind.ProgBar(50000)\n",
    "df = pd.DataFrame()\n",
    "for s in ('test', 'train'):\n",
    "    for l in ('pos', 'neg'):\n",
    "        path = os.path.join(basepath, s, l)\n",
    "        for file in sorted(os.listdir(path)):\n",
    "            with open(os.path.join(path, file), \n",
    "                      'r', encoding='utf-8') as infile:\n",
    "                txt = infile.read()\n",
    "            df = df.append([[txt, labels[l]]], \n",
    "                           ignore_index=True)\n",
    "            pbar.update()\n",
    "df.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and save the assembled data as CSV file\n",
    "- pickle the DataFrame as a binary file for faster load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "df = df.reindex(np.random.permutation(df.index)) # randomize files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1      OK... so... I really like Kris Kristofferson a...          0\n",
       "2      ***SPOILER*** Do not read this, if you think a...          0\n",
       "3      hi for all the people who have seen this wonde...          1\n",
       "4      I recently bought the DVD, forgetting just how...          0\n",
       "...                                                  ...        ...\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv format\n",
    "df.to_csv('data/movie_data.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save DataFrame as a pickle dump\n",
    "pickle.dump(df, open('data/movie_data.pd', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly load the pickled file as DataFrame\n",
    "df = pickle.load(open('data/movie_data.pd', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1      OK... so... I really like Kris Kristofferson a...          0\n",
       "2      ***SPOILER*** Do not read this, if you think a...          0\n",
       "3      hi for all the people who have seen this wonde...          1\n",
       "4      I recently bought the DVD, forgetting just how...          0\n",
       "...                                                  ...        ...\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag-of-words model\n",
    "- ML algorithms only work on numerical values\n",
    "- need to encode/transform text data into numerical values using **bag-of-words** model\n",
    "- **bag-of-words** technique allow us to represent text as numerical feature vectors:\n",
    "    1. extract all the unieque tokens -- e.g., words -- from entire document\n",
    "    2. construct feature vector that contains the word frequency in the particular document \n",
    "    3. order of the words in the document doesn't matter - hence bag-of-words\n",
    "- since the unique words in each document represent only a small subset of all the words in the bag-of-words vocabulary, the feature vector will be **sparse** mostly consisting of zeros\n",
    "\n",
    "### transform words into feature vectors\n",
    "- use `CountVectorizer` class implemented in scikit-learn\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "- `CountVectorizer` takes an array of text data and returns a bag-of-words vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "docs = np.array([\n",
    "        'The sun is shining',\n",
    "        'The weather is sweet',\n",
    "        'The sun is shining, the weather is sweet, and one and one is two'])\n",
    "bag = count.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 6,\n",
       " 'sun': 4,\n",
       " 'is': 1,\n",
       " 'shining': 3,\n",
       " 'weather': 8,\n",
       " 'sweet': 5,\n",
       " 'and': 0,\n",
       " 'one': 2,\n",
       " 'two': 7}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at the vocabulary_ contents of count object\n",
    "count.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 1, 0, 1],\n",
       "       [2, 3, 2, 1, 1, 1, 2, 1, 1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag-of-words feature vector\n",
    "- the values in the feature vectors are also called the **raw term frequencies**\n",
    "    - $x^i = tf(t^i, d)$\n",
    "    - the number of times a term, $t$ appears in a document, $d$\n",
    "- indices of terms are usually assigned alphabetically\n",
    "\n",
    "### N-gram models\n",
    "- the above model is **1-gram** or **unigram** model\n",
    "    - each item or token in the vocabulary represents a single word\n",
    "- if the sentence is: \"The sun is shining\"\n",
    "- 1-gram: \"the\", \"sun\", \"is\", \"shining\"\n",
    "- 2-gram: \"the sun\", \"sun is\", \"is shining\"\n",
    "- `CountVectorizer` class allows us to use different n-gram models via its `ngram_range` parameter\n",
    "- e.g. ngram_range(2, 2) will use 2-gram model\n",
    "\n",
    "## Assess word relevency via term frequency-inverse document frequency\n",
    "- words ofter occur across multiple documents from all the classes (positive and negative in IMDb)\n",
    "- frequentyly occuring words don't contain discriminatory information\n",
    "- **tf-idf** model can be used to downweight these frequently occuring words in the feature vectors\n",
    "    - $tf\\mbox{-}idf(t, d) = tf(t, d) \\times idf(t, d)$\n",
    "    - $ idf(t, d) = log\\frac{n_d}{1+df(d, t)}$\n",
    "    - $n_d$ - total number of documents\n",
    "    - $df(d, t)$ - number of documents, $d$ that contain the term $t$\n",
    "    - $log$ ensures that low document frequencies are not given too much weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
